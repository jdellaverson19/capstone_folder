{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a scaled version of the model creation for the LSTM. In particular, since we'll be regularly creating a model for every stock we're interested in forecasting on a fairly regular basis, we've opted to only predict on one feature (the closing price), and to use an extremely limited LSTM (in terms of layers), with a limited number of epochs. In general, we also train this on a limited amount of data (e.g. since 2023) to improve performance. We've tested various iterations of time and number of features, and this seems to hit a good combination of performance and speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# For reading stock data from yahoo\n",
    "from pandas_datareader.data import DataReader\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "import mlflow\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "# For time stamps\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def makeModel(trainStock, trainStartDate):\n",
    "    mlflow.autolog()\n",
    "    df2 = pdr.get_data_yahoo(trainStock, start=trainStartDate, end=datetime.now())\n",
    "    # Show the data\n",
    "    # Create a new dataframe with only the 'Close column\n",
    "    data = df2.filter([\"Close\"])\n",
    "    # Convert the dataframe to a numpy array\n",
    "    dataset = data.values\n",
    "    # Get the number of rows to train the model on\n",
    "    training_data_len = int(np.ceil(len(dataset) * 0.95))\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "    train_data = scaled_data[0 : int(training_data_len), :]\n",
    "    # Split the data into x_train and y_train data sets\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for i in range(60, len(train_data)):\n",
    "        x_train.append(train_data[i - 60 : i, 0])\n",
    "        y_train.append(train_data[i, 0])\n",
    "        if i <= 61:\n",
    "            print(\"61\")\n",
    "\n",
    "    # Convert the x_train and y_train to numpy arrays\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "    # Reshape the data\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "\n",
    "    # Train the model with mlflow\n",
    "    mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "    mlflow.set_experiment(f\"{trainStock}_{trainStartDate}_experiment\")\n",
    "    with mlflow.start_run() as run:\n",
    "        model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=1,\n",
    "            epochs=2,\n",
    "            callbacks=[mlflow.keras.MlflowCallback()],\n",
    "        )\n",
    "\n",
    "        # model.fit(x_train, y_train, batch_size=1, epochs=3)\n",
    "        test_data = scaled_data[training_data_len - 60 :, :]\n",
    "        # Create the data sets x_test and y_test\n",
    "        x_test = []\n",
    "        y_test = dataset[training_data_len:, :]\n",
    "        for i in range(60, len(test_data)):\n",
    "            x_test.append(test_data[i - 60 : i, 0])\n",
    "\n",
    "        # Convert the data to a numpy array\n",
    "        x_test = np.array(x_test)\n",
    "\n",
    "        # Reshape the data\n",
    "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "        # Get the models predicted price values\n",
    "        predictions = model.predict(x_test)\n",
    "        predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "        # Get the root mean squared error (RMSE)\n",
    "        rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        model.save(\n",
    "            rf\"./models/{trainStock}.keras\",\n",
    "        )\n",
    "        joblib.dump(\n",
    "            scaler,\n",
    "            rf\"./models/{trainStock}.gz\",\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
